---
title: "ADVANCE DATA MINING AND PREDICTIVE ANALYTICS - 3"
author: "shiva gadila"
date: "2023-12-06"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

QA1. What is the difference between SVM with hard margin and soft margin?

In Support Vector Machines (SVM), there are two main approaches: hard margin and soft margin.

Hard Margin SVM:
Imagine you have data points of two different classes, and you want to draw a line (hyperplane) that perfectly separates them.
This works well when the data is cleanly separable, but in real life, there might be some noisy or outlier points.
Hard Margin SVM doesn't handle these outliers gracefully. It insists on a perfect division, and if there's even one misclassified point, it struggles.

Soft Margin SVM:
Understanding that perfect separation might not be achievable in the real world, especially with noisy data, the soft margin approach is more forgiving.
It introduces a concept called "slack variable." This allows for a bit of flexibility, meaning it permits some points to be on the wrong side of the dividing line.
The challenge now becomes finding a balance between having a wide margin (space between classes) and allowing for a few misclassifications.
There's a parameter called "C" that decides how much penalty is given for each misclassified point. You can think of it as the cost of allowing mistakes.

Summary:
Hard Margin: Insists on a perfect division, not great with noisy data.
Soft Margin: More flexible, accepts some misclassifications, and adjusts the balance with the "C" parameter.
In simple terms, it's like trying to draw a line between two groups of points. Hard Margin wants a flawless line, while Soft Margin allows for a bit of messiness, deciding how much mess is acceptable with the "C" parameter. It's a way of handling the imperfect nature of real-world data.  

QA2. What is the role of the cost parameter, C, in SVM (with soft margin) classifie?

The importance of the cost parameter, C, in SVM with a soft margin cannot be overstated. It acts as the guiding force in balancing the priorities of maximizing the margin and minimizing classification errors.

SVM focuses on creating a broader margin to enhance generalization, acknowledging the challenges of achieving perfect separation in real-world scenarios. C allows for some misclassifications but strives to keep them minimal while maintaining a significant margin.

The delicate balance controlled by the C parameter involves a trade-off. Lower C values prioritize a wider margin, accepting a higher tolerance for misclassifications. Conversely, higher C values emphasize reducing misclassifications, potentially leading to a narrower margin.

The impact of the chosen C value is significant. A high C risks overfitting by closely fitting the training data, capturing noise and outliers. In contrast, a low C may result in underfitting as the model leans heavily towards maximizing the margin, potentially neglecting some misclassifications.

Selecting the right C value is crucial for optimal SVM performance. Techniques like cross-validation help explore various C values, ensuring the choice that delivers the best performance on a validation set. This meticulous approach ensures the development of a well-balanced SVM model proficient in managing both margin maximization and classification error minimization.

Q3. Will the following perceptron be activated (2.8 is the activation threshold)?

Activation function = (input 1 x weight 1) + (input 2 x weight 2) = (0.1 x 0.8) + (11.1 x -0.2) 

= 0.08 - 2.22

= -2.14

The activation function value is -2.14, which falls below the activation threshold of 2.8. Consequently, the perceptron will remain inactive in this scenario. 

QA4. What is the role of alpha, the learning rate in the delta rule?

In the delta rule, a widely used algorithm for adjusting neural network weights during training, the learning rate, represented by the symbol alpha (α), plays a crucial role. Alpha is a hyperparameter that determines the size of the steps taken for weight updates generated by the delta rule.

Here's how it works: The delta rule calculates the error between the predicted output of the neural network and the actual target output. This error is then utilized to tweak the network's weights, aiming to enhance its overall performance. The extent of weight adjustment is linked to both the magnitude of the error and the learning rate.

Choosing the right value for alpha is key. A higher alpha leads to more substantial weight updates, facilitating faster convergence of weights. However, this can also result in overshooting the optimal weights and hinder convergence. Conversely, a lower alpha results in smaller weight updates and a longer convergence process. While this approach may assist in reaching a more accurate minimum, it requires patience during training.

Selecting an appropriate learning rate is a critical aspect of the delta rule, impacting the algorithm's performance. A common strategy involves starting with a small alpha, such as 0.1 or 0.01, and then fine-tuning it through experimentation to achieve optimal results on the training data.      

PART B 

```{r}

#QB1. Build a linear SVM regression model to predict Sales based on all other attributes ("Price","Advertising", "Population", "Age", "Income" and "Education"). Hint: use caret train() with method set to “svmLinear”. What is the R-squared of the model?

library(ISLR)
library(dplyr)
library(glmnet)
library(caret)

```

```{r}
Carseats_Filtered <- Carseats %>% select("Sales", "Price", "Advertising","Population","Age","Income","Education")
```

```{r}
set.seed(123)
trainIndex <- createDataPartition(Carseats_Filtered$Sales, p = 0.7, list = FALSE)
Train_Data <- Carseats_Filtered[trainIndex, ]
Test_Data <- Carseats_Filtered[-trainIndex, ]

```

```{r}
#Set up the model.
Support_Vector_Machine_Model <- train(Sales ~.,
               data = Train_Data,
               method = "svmLinear",
               trControl = trainControl(method ="cv",number
                                        = 10))

```

```{r}
#Presenting the model's summary information.
summary(Support_Vector_Machine_Model)
```

```{r}
#Make predictions using the test dataset.
Predictions <- predict(Support_Vector_Machine_Model, newdata = Test_Data)
```

```{r}
#Determine the R-squared value.
R_squared<- postResample(Predictions, Test_Data$Sales)
R_squared
```

```{r}
#QB2. Customize the search grid by checking the model’s performance for C parameter of 0.1,.5,1 and 10 using 2 repeats of 5-fold cross validation.

library(caret)
Grid <- expand.grid(C = c(0.1,0.5,1,10))
trctrl2 <- trainControl(method = "repeatedcv", number = 5,repeats = 2) 
svm_Linear_Grid <- train(Sales~., data = Carseats_Filtered, method = "svmLinear",
                         trControl=trctrl2,
                         preProcess = c("center", "scale"),
                         tuneGrid = Grid,
                         tuneLength = 10)
svm_Linear_Grid

```


```{r}
#QB3. Train a neural network model to predict Sales based on all other attributes (“Price”,“Advertising”, “Population”, “Age”, “Income” and “Education”). Hint: use caret train() with method set to “nnet”. What is the R-square of the model with the best hyper parameters (using default caret search grid) – hint: don’t forget to scale the data.


#Data scaling
scaled <- preProcess(Carseats_Filtered[-1], method = "scale")
train <- predict(scaled, Carseats_Filtered[-1])
#Train control
set.seed(27)
folds <- trainControl(method = "repeatedcv", 
                     number = 5, 
                     repeats = 2,
                     verboseIter = FALSE)
# Using default search grid, training the neural network model 
set.seed(123)
nnet_Cars <- train(Sales~.,data = Carseats_Filtered ,
                    method = "nnet",
                    trControl = folds)
nnet_Cars

#The optimal model was chosen based on the RMSE (root mean squared error), featuring a size of 1 and a decay of 0. The RMSE for this model was 7.081637, accompanied by a corresponding MAE (mean absolute error) value of 6.511536. While the Rsquared value was 'not available' for the optimal model, it ranged from NaN to 0.02538470 for other models.
```

```{r}
#QB4 - “Consider the following input: Sales=9, Price=6.54, Population=124, Advertising=0, Age=76, Income= 110, Education=10 What will be the estimated Sales for this record using the above neuralnet model?”

Sales <- c(9)
Price <- c(6.54)
Population <- c(124)
Advertising <- c(0)
Age <- c(76)
Income <- c(110)
Education <- c(10)
Test <- data.frame(Sales, Price, Population, Advertising, Age, Income, Education)
```

```{r}
# Making Predictions
Predicting_sales <- predict(nnet_Cars, Test)
Predicting_sales
```



